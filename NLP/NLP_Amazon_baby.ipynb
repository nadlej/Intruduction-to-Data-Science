{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "NLP_Amazon_baby.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJfAJTIUH_KE"
      },
      "source": [
        "### Today we are going to perform the simple classification of the amazon reviews' sentiment.\n",
        "\n",
        "### Please, download the dataset amazon_baby.csv."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "APJ3oLvgH_KE",
        "outputId": "a7d8d94e-b28b-4dcf-c3a0-9d97f2fa31f2"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    import string\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    return text.translate(translator)\n",
        "\n",
        "baby_df = pd.read_csv('amazon_baby.csv')\n",
        "baby_df.head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>review</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Planetwise Flannel Wipes</td>\n",
              "      <td>These flannel wipes are OK, but in my opinion ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Planetwise Wipe Pouch</td>\n",
              "      <td>it came early and was not disappointed. i love...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
              "      <td>Very soft and comfortable and warmer than it l...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
              "      <td>This is a product well worth the purchase.  I ...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
              "      <td>All of my kids have cried non-stop when I trie...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                name  ... rating\n",
              "0                           Planetwise Flannel Wipes  ...      3\n",
              "1                              Planetwise Wipe Pouch  ...      5\n",
              "2                Annas Dream Full Quilt with 2 Shams  ...      5\n",
              "3  Stop Pacifier Sucking without tears with Thumb...  ...      5\n",
              "4  Stop Pacifier Sucking without tears with Thumb...  ...      5\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uI-4NSIsH_KF"
      },
      "source": [
        "## Exercise 1 (data preparation)\n",
        "a) Remove punctuation from reviews using the given function.   \n",
        "b) Replace all missing (nan) revies with empty \"\" string.  \n",
        "c) Drop all the entries with rating = 3, as they have neutral sentiment.   \n",
        "d) Set all positive ($\\geq$4) ratings to 1 and negative($\\leq$2) to -1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcQuWet9H_KF",
        "outputId": "1c4b37fd-aa2c-4752-9030-c74463dea2c1"
      },
      "source": [
        "#a)\n",
        "baby_df[\"review\"] = [remove_punctuation(str(baby_df['review'][x])) for x in range(0,baby_df.shape[0])]\n",
        "\n",
        "\n",
        "#short test: \n",
        "baby_df[\"review\"][4] == 'All of my kids have cried nonstop when I tried to ween them off their pacifier until I found Thumbuddy To Loves Binky Fairy Puppet  It is an easy way to work with your kids to allow them to understand where their pacifier is going and help them part from itThis is a must buy book and a great gift for expecting parents  You will save them soo many headachesThanks for this book  You all rock'\n",
        "remove_punctuation(baby_df[\"review\"][4]) == 'All of my kids have cried nonstop when I tried to ween them off their pacifier until I found Thumbuddy To Loves Binky Fairy Puppet  It is an easy way to work with your kids to allow them to understand where their pacifier is going and help them part from itThis is a must buy book and a great gift for expecting parents  You will save them soo many headachesThanks for this book  You all rock'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNNIrQwwH_KF",
        "outputId": "e3731683-df6a-477c-a976-33bc3517e6c8"
      },
      "source": [
        "#b)\n",
        "baby_df['review'] = baby_df['review'].fillna(\" \")\n",
        "\n",
        "#short test:\n",
        "baby_df[\"review\"][38] == baby_df[\"review\"][38]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RH4lu4VH_KG",
        "outputId": "3d9f1438-e61f-4a8a-a8c8-6ac15acd92f6"
      },
      "source": [
        "#c)\n",
        "baby_df = baby_df[baby_df.rating != 3] \n",
        "\n",
        "#short test:\n",
        "sum(baby_df[\"rating\"] == 3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JW-OJPtCH_KG",
        "outputId": "988b6af4-f2c2-41f5-9aec-a834d6e7f47c"
      },
      "source": [
        "#d) \n",
        "baby_df['rating'] = baby_df['rating'].replace([2,1],-1)\n",
        "baby_df['rating'] = baby_df['rating'].replace([4,5],1)\n",
        "\n",
        "\n",
        "print(np.unique(baby_df['rating']))\n",
        "\n",
        "#short test:\n",
        "sum(baby_df[\"rating\"]**2 != 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-1  1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eJgrAcYH_KG"
      },
      "source": [
        "## CountVectorizer\n",
        "In order to analyze strings, we need to assign them numerical values. We will use one of the simplest string representation, which transforms strings into the $n$ dimensional vectors. The number of dimensions will be the size of our dictionary, and then the values of the vector will represent the number of appereances of the given word in the sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHievXtvH_KG",
        "outputId": "6b75f4dd-6b46-4a2e-a82d-0202baa53df7"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "reviews_train_example = [\"We like apples\",\n",
        "                   \"We hate oranges\",\n",
        "                   \"I adore bananas\",\n",
        "                   \"We like like apples and oranges\",\n",
        "                   \"They dislike bananas\"]\n",
        "\n",
        "X_train_example = vectorizer.fit_transform(reviews_train_example)\n",
        "\n",
        "print(vectorizer.get_feature_names())\n",
        "print(X_train_example.todense())\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['adore', 'and', 'apples', 'bananas', 'dislike', 'hate', 'like', 'oranges', 'they', 'we']\n",
            "[[0 0 1 0 0 0 1 0 0 1]\n",
            " [0 0 0 0 0 1 0 1 0 1]\n",
            " [1 0 0 1 0 0 0 0 0 0]\n",
            " [0 1 1 0 0 0 2 1 0 1]\n",
            " [0 0 0 1 1 0 0 0 1 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6alTcbZOH_KG",
        "outputId": "e74d2a28-db91-4b28-e903-2278394780d1"
      },
      "source": [
        "reviews_test_example = [\"They like bananas\",\n",
        "                   \"We hate oranges bananas and apples\",\n",
        "                   \"We love bananas\"] #New word!\n",
        "\n",
        "X_test_example = vectorizer.transform(reviews_test_example)\n",
        "\n",
        "print(vectorizer.get_feature_names())\n",
        "print(X_test_example.todense())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['adore', 'and', 'apples', 'bananas', 'dislike', 'hate', 'like', 'oranges', 'they', 'we']\n",
            "[[0 0 0 1 0 0 1 0 1 0]\n",
            " [0 1 1 1 0 1 0 1 0 1]\n",
            " [0 0 0 1 0 0 0 0 0 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cShrUuMXH_KG"
      },
      "source": [
        "We should acknowledge few facts. Firstly, CountVectorizer does not take order into account. Secondly, it ignores one-letter words (this can be changed during initialization). Finally, for test values, CountVectorizer ignores words which are not in it's dictionary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FPgbrcwH_KG"
      },
      "source": [
        "## Exercise 2 \n",
        "a) Split dataset into training and test sets.     \n",
        "b) Transform reviews into vectors using CountVectorizer. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aON8V7sdH_KG"
      },
      "source": [
        "#a)\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(baby_df['review'],baby_df['rating'],\n",
        "                                                    test_size=0.33, random_state=42)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mixjM4pQH_KG"
      },
      "source": [
        "#b)\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "X_train_v = vectorizer.fit_transform(X_train)\n",
        "\n",
        "X_test_v = vectorizer.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMEFrQaYH_KG"
      },
      "source": [
        "## Exercise 3 \n",
        "a) Train LogisticRegression model on training data (reviews processed with CountVectorizer, ratings as they were).   \n",
        "b) Print 10 most positive and 10 most negative words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXdzALACH_KG"
      },
      "source": [
        "#a)\n",
        "model = LogisticRegression(max_iter=10000)\n",
        "\n",
        "start = timer()\n",
        "\n",
        "model.fit(X_train_v, y_train)\n",
        "\n",
        "end = timer()\n",
        "\n",
        "time_1 = end - start"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUv-PBlJH_KG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c13f0e0-8d3e-4e1a-9488-5c4899339076"
      },
      "source": [
        "#b)\n",
        "\n",
        "best = np.argsort(model.coef_)\n",
        "print(\"10 most positive: \", np.array(vectorizer.get_feature_names())[best[0,-10:]])\n",
        "print(\"10 most negative: \",np.array(vectorizer.get_feature_names())[best[0, 0:10]])\n",
        "\n",
        "#hint: model.coef_, vectorizer.get_feature_names()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 most positive:  ['perfect' 'sooner' 'glad' 'rich' 'saves' 'ply' 'minor' 'lifesaver' 'con'\n",
            " 'wonderfully']\n",
            "10 most negative:  ['dissapointed' 'worst' 'worthless' 'useless' 'poorly' 'nope'\n",
            " 'disappointing' 'disappointed' 'disappointment' 'slowflow']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2yC66QpCNtw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e0645633-e37c-45e1-e025-0c7d7eaf3fac"
      },
      "source": [
        "\"\"\"\n",
        "As we can see, when 10 most negative words are crearly negative, some words from these most positive\n",
        "aren't, like sooner or minor.\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nAs we can see, when 10 most negative words are crearly negative, some words from these most positive\\naren't, like sooner or minor.\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUeao3S_H_KG"
      },
      "source": [
        "## Exercise 4 \n",
        "a) Predict the sentiment of test data reviews.   \n",
        "b) Predict the sentiment of test data reviews in terms of probability.   \n",
        "c) Find five most positive and most negative reviews.   \n",
        "d) Calculate the accuracy of predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjYK5v7pH_KG"
      },
      "source": [
        "#a)\n",
        "y_predict = model.predict(X_test_v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B428YN_oH_KG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2de1cd20-1efe-47c2-a4ea-2f186f0cbba8"
      },
      "source": [
        "#b)\n",
        "y_proba = model.predict_proba(X_test_v)\n",
        "y_proba\n",
        "#hint: model.predict_proba()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.51498469, 0.48501531],\n",
              "       [0.82814556, 0.17185444],\n",
              "       [0.98794345, 0.01205655],\n",
              "       ...,\n",
              "       [0.38584744, 0.61415256],\n",
              "       [0.0120209 , 0.9879791 ],\n",
              "       [0.00985932, 0.99014068]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QBl3nQaDId5"
      },
      "source": [
        "\"\"\"\n",
        "Each word has its own probability, that the y-value is positive(first column) or negative(second column).\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NroVpavIH_KG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c0e2ece-a2cc-4a30-b1d3-37ec8f61e90d"
      },
      "source": [
        "#c)\n",
        "\n",
        "data = np.argsort(y_proba[:,1])[-5:]\n",
        "\n",
        "print(X_test.iloc[data])\n",
        "print(y_test.iloc[data])\n",
        "\n",
        "data = np.argsort(y_proba[:,1])[:5]\n",
        "\n",
        "print(X_test.iloc[data])\n",
        "print(y_test.iloc[data])\n",
        "\n",
        "\n",
        "#hint: use the results of b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "57108     I started wearing the Babyplus when I was 18 w...\n",
            "180646    After much research I purchased an Urbo2 Its e...\n",
            "100166    I bought this carrier when my daughter was abo...\n",
            "129722    This is a review of the 2012 Bumbleride Flite ...\n",
            "168086    Buttons vs Best Bottoms reviewFirst thing I wa...\n",
            "Name: review, dtype: object\n",
            "57108     1\n",
            "180646    1\n",
            "100166    1\n",
            "129722    1\n",
            "168086    1\n",
            "Name: rating, dtype: int64\n",
            "147902    My disappointment with this product prompted m...\n",
            "175191    I had to return this stroller for three reason...\n",
            "77072     I thought it sounded great to have different t...\n",
            "89902     I am so incredibly disappointed with the strol...\n",
            "133297    The first monitor broke within 1 month of use ...\n",
            "Name: review, dtype: object\n",
            "147902   -1\n",
            "175191   -1\n",
            "77072    -1\n",
            "89902    -1\n",
            "133297   -1\n",
            "Name: rating, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2I5pJ3lzDhUt"
      },
      "source": [
        "\"\"\"\n",
        "After printing the y-values of the 5 most positive and negative reviews, we can see that their y-values are correct.\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrdLQV2rH_KG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ff6b365-f771-4941-e7da-5153cd111728"
      },
      "source": [
        "#d) \n",
        "print(model.score(X_train_v, y_train))\n",
        "print(model.score(X_test_v, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9708743947083411\n",
            "0.930945501462865\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yidJJ__CD8Il"
      },
      "source": [
        "\"\"\"\n",
        "The accuracy is 0.04 higher for the training set than for the test set.\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyqiEdwlH_KG"
      },
      "source": [
        "## Exercise 5\n",
        "In this exercise we will limit the dictionary of CountVectorizer to the set of significant words, defined below.\n",
        "\n",
        "\n",
        "a) Redo exercises 2-5 using limited dictionary.   \n",
        "b) Check the impact of all the words from the dictionary.   \n",
        "c) Compare accuracy of predictions and the time of evaluation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5TASeNYH_KG"
      },
      "source": [
        "significant_words = ['love','great','easy','old','little','perfect','loves','well','able','car','broke','less','even','waste','disappointed','work','product','money','would','return']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUWsHrwIH_KG"
      },
      "source": [
        "#a)\n",
        "vectorizer_2 = CountVectorizer(vocabulary=significant_words)\n",
        "X_train_2v = vectorizer_2.fit_transform(X_train)\n",
        "X_test_2v = vectorizer_2.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ob69696Ag9EQ"
      },
      "source": [
        "model_2 = LogisticRegression(max_iter=10000)\n",
        "\n",
        "start_2 = timer()\n",
        "\n",
        "model_2.fit(X_train_2v, y_train)\n",
        "\n",
        "end_2 = timer()\n",
        "\n",
        "time_2 = end_2 - start_2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHXrIwgo9JDN",
        "outputId": "6b4b3f08-d9a4-4346-d76f-fc8297e49a27"
      },
      "source": [
        "best_2 = np.argsort(model_2.coef_)\n",
        "print(\"10 most positive: \", np.array(vectorizer_2.get_feature_names())[best_2[0,-10:]])\n",
        "print(\"10 most negative: \",np.array(vectorizer_2.get_feature_names())[best_2[0, 0:10]])\n",
        "\n",
        "y_predict_2 = model_2.predict(X_test_2v)\n",
        "y_proba_2 = model_2.predict_proba(X_test_2v)\n",
        "\n",
        "data_2 = np.argsort(y_proba_2[:,1])[-5:]\n",
        "data_2 = np.argsort(y_proba_2[:,1])[:5]\n",
        "\n",
        "print(X_test.iloc[data_2])\n",
        "print(y_test.iloc[data_2])\n",
        "\n",
        "print(X_test.iloc[data_2])\n",
        "print(y_test.iloc[data_2])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 most positive:  ['old' 'car' 'able' 'well' 'little' 'great' 'easy' 'love' 'perfect'\n",
            " 'loves']\n",
            "10 most negative:  ['disappointed' 'return' 'waste' 'broke' 'money' 'work' 'even' 'would'\n",
            " 'product' 'less']\n",
            "41581     Looks really cute however the cloth smells fun...\n",
            "168391    I loved all the features of the car seat  It i...\n",
            "35763     Day 1 Assembled it Had it up and running playi...\n",
            "56798     I was excited to give these instruments to my ...\n",
            "111079    I searched for Baby Blanket Made in the USA an...\n",
            "Name: review, dtype: object\n",
            "41581    -1\n",
            "168391    1\n",
            "35763    -1\n",
            "56798    -1\n",
            "111079   -1\n",
            "Name: rating, dtype: int64\n",
            "41581     Looks really cute however the cloth smells fun...\n",
            "168391    I loved all the features of the car seat  It i...\n",
            "35763     Day 1 Assembled it Had it up and running playi...\n",
            "56798     I was excited to give these instruments to my ...\n",
            "111079    I searched for Baby Blanket Made in the USA an...\n",
            "Name: review, dtype: object\n",
            "41581    -1\n",
            "168391    1\n",
            "35763    -1\n",
            "56798    -1\n",
            "111079   -1\n",
            "Name: rating, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6k5NEedgEp-m"
      },
      "source": [
        "\"\"\"\n",
        "As you can see, the model classified the words in the dictionary quite well.\n",
        "After printing the 5 most positive and negative reviews, we can see\n",
        "that one of the most negative reviews is actually positive.\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-I5ZCWYH_KG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cb99403-699e-4e45-e6c7-e9e4fb1d5f27"
      },
      "source": [
        "#b)\n",
        "for w, k in sorted(zip(significant_words, model_2.coef_[0]), key = lambda x: x[1]):\n",
        "  print(\"{} and impact: {}\".format(w, k))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "disappointed and impact: -2.387758373661248\n",
            "return and impact: -2.0878135743686914\n",
            "waste and impact: -1.9981697871878579\n",
            "broke and impact: -1.6429197636994468\n",
            "money and impact: -0.9403220306130846\n",
            "work and impact: -0.6213267170831115\n",
            "even and impact: -0.49910674931051097\n",
            "would and impact: -0.3508212078627339\n",
            "product and impact: -0.3075479144735849\n",
            "less and impact: -0.20315523738278388\n",
            "old and impact: 0.06100797468095392\n",
            "car and impact: 0.08451117821537883\n",
            "able and impact: 0.2062102887977539\n",
            "well and impact: 0.49598179029584777\n",
            "little and impact: 0.5190223589367308\n",
            "great and impact: 0.912380499218431\n",
            "easy and impact: 1.1796233668038638\n",
            "love and impact: 1.3584748195710263\n",
            "perfect and impact: 1.5133629421180903\n",
            "loves and impact: 1.7033230640221935\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8dlUIA5FzCv"
      },
      "source": [
        "\"\"\"\n",
        "The word with the most negative impact is \"disappointed\" and the word with\n",
        "the most positive impact is \"loves\".\n",
        "Some words, like \"old\" and \"car\" have positive impact, but it is very low.\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HM1bKP6mH_KG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e0357de-a3a7-442e-d761-0c29492cf9ae"
      },
      "source": [
        "#c)\n",
        "print(\"Accuracy of second model on training set: \", model.score(X_train_v, y_train))\n",
        "print(\"Accuracy of second model on training set: \", model.score(X_test_v, y_test))\n",
        "print(\"Time of evaluation: \", time_1)\n",
        "print()\n",
        "print(\"Accuracy of second model on training set: \", model_2.score(X_train_2v, y_train))\n",
        "print(\"Accuracy of second model on training set: \", model_2.score(X_test_2v, y_test))\n",
        "print(\"Time of evaluation: \", time_2)\n",
        "\n",
        "#hint: %time, %timeit"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of second model on training set:  0.9708743947083411\n",
            "Accuracy of second model on training set:  0.930945501462865\n",
            "Time of evaluation:  83.07514877200003\n",
            "\n",
            "Accuracy of second model on training set:  0.8672341415823063\n",
            "Accuracy of second model on training set:  0.8675062239909865\n",
            "Time of evaluation:  0.42288639699995656\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZHxA2ESGuG-"
      },
      "source": [
        "\"\"\"\n",
        "First model took more time than the second.\n",
        "The accuracy difference is 0.1 for training set and 0.07 for the testing set.\n",
        "An interesting fact is that the testing and training accuracy in the second model are similar.\n",
        "It can be concluded that it doesn't take long to build a pretty good model, but if we decide \n",
        "to build a better one, it will take much longer.\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}